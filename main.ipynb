{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate  # for rendering board\n",
    "from enum import Enum\n",
    "from random import randint, choice\n",
    "from copy import copy\n",
    "\n",
    "# environment possible actions: swipe to left, right, up, down\n",
    "class Action(Enum):\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    Left = 1\n",
    "    Right = 2\n",
    "    Up = 3\n",
    "    Down = 4\n",
    "\n",
    "\n",
    "class GameEnvironment:\n",
    "    def __init__(self, board_size=3, target=64, initial_state=None):\n",
    "        if initial_state == None:\n",
    "            # start with empty board\n",
    "            self.__initial_state = np.zeros([board_size, board_size])\n",
    "        else:\n",
    "            # copy to prevent aliassing\n",
    "            self.__initial_state = copy(initial_state)\n",
    "\n",
    "        # dynamic board size\n",
    "        self.board_size = board_size\n",
    "        self.target = target\n",
    "        self.__state = self.__initial_state\n",
    "        self.__possible_states = []\n",
    "        # maybe to remove\n",
    "        # self.__calculate_possible_states(self.__initial_state)\n",
    "\n",
    "    # maybe to remove - iterate over all possible states\n",
    "    def __calculate_possible_states(self, state):\n",
    "        actions = self.get_possible_actions(state)\n",
    "        for action in actions:\n",
    "            new_state = copy(state)\n",
    "            if state.count(X) == state.count(O):\n",
    "                new_state[action] = X\n",
    "            else:\n",
    "                new_state[action] = O\n",
    "            self.__possible_states.append(new_state)\n",
    "            if not self.is_done(new_state):\n",
    "                self.__calculate_possible_states(new_state)\n",
    "\n",
    "    def reset(self):\n",
    "        self.__state = self.__initial_state\n",
    "        return self.__state\n",
    "\n",
    "    # perform action on environment\n",
    "    def __calculate_transition(self, action):\n",
    "        if self.is_done():\n",
    "            return self.__state\n",
    "\n",
    "        # 1. change the state to reflect the move by the agent,\n",
    "        # 2. merge same value tiles\n",
    "\n",
    "        # swipe to left\n",
    "        if action == Action.Left:\n",
    "            self.__state = self.swipeToLeft(self.__state)\n",
    "            self.__state = self.mergeToLeft(self.__state)\n",
    "        # swipe to right\n",
    "        elif action == Action.Right:\n",
    "            self.__state = self.swipeToRight(self.__state)\n",
    "            self.__state = self.mergeToRight(self.__state)\n",
    "        elif action == Action.Up:\n",
    "            # take transpose, swipe, then re-take transpose\n",
    "            temp_state = self.transpose(self.__state)\n",
    "            temp_state = self.swipeToLeft(temp_state)\n",
    "            self.__state = self.transpose(temp_state)\n",
    "\n",
    "            # take transpose, merge same tiles, then re-take transpose\n",
    "            temp_state = self.transpose(self.__state)\n",
    "            temp_state = self.mergeToLeft(temp_state)\n",
    "            self.__state = self.transpose(temp_state)\n",
    "        elif action == Action.Down:\n",
    "            # take transpose\n",
    "            temp_state = self.transpose(self.__state)\n",
    "            temp_state = self.swipeToRight(temp_state)\n",
    "            self.__state = self.transpose(temp_state)\n",
    "\n",
    "            # take transpose, merge same tiles, then re-take transpose\n",
    "            temp_state = self.transpose(self.__state)\n",
    "            temp_state = self.mergeToRight(temp_state)\n",
    "            self.__state = self.transpose(temp_state)\n",
    "\n",
    "        # 3. generate a new tile on empty cells\n",
    "\n",
    "        empty_state = self.get_possible_actions(self.__state)\n",
    "\n",
    "        if len(empty_state) > 0:\n",
    "            # possible generated tile values\n",
    "            possible_gen_tiles = [2, 4]\n",
    "            # generate new tile at random empty cell\n",
    "            row, col = choice(empty_state)\n",
    "            self.__state[row][col] = possible_gen_tiles[randint(0, 1)]\n",
    "\n",
    "        return self.__state\n",
    "\n",
    "    def swipeToLeft(self, state):\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                # [0,2,2]: if current cell is empty, swap with the right one\n",
    "                if state[i][j] == 0:\n",
    "\n",
    "                    # k is the offset of the first found tile\n",
    "                    for k in range(1, self.board_size - j):\n",
    "                        if state[i][j + k] != 0:\n",
    "                            self.swap(state, i, j, i, j + k)\n",
    "                            break\n",
    "        return state\n",
    "\n",
    "    def mergeToLeft(self, state):\n",
    "        # merge same tiles together\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    right_tile = state[i][j + 1]\n",
    "                    if right_tile == current_tile:\n",
    "                        # merge same tiles together\n",
    "                        state[i][j] = current_tile * 2\n",
    "                        state[i][j + 1] = 0\n",
    "                        # shift to the left other tiles\n",
    "                        for k in range(j + 1, self.board_size - 1):\n",
    "                            # current tile equal right tile\n",
    "                            state[i][j + k] = state[i][j + k + 1]\n",
    "\n",
    "                        # last cell is empty\n",
    "                        state[i][self.board_size - 1] = 0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def swipeToRight(self, state):\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                # [2,2,0]: if current cell is empty, swap with the left one\n",
    "                if state[i][j] == 0:\n",
    "\n",
    "                    # k is the offset of the first found tile\n",
    "                    for k in range(1, j + 1):\n",
    "                        if state[i][j - k] != 0:\n",
    "\n",
    "                            self.swap(state, i, j, i, j - k)\n",
    "                            break\n",
    "        return state\n",
    "\n",
    "    def mergeToRight(self, state):\n",
    "        # merge same tiles together\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    left_tile = state[i][j - 1]\n",
    "                    if left_tile == current_tile:\n",
    "                        # merge same tiles together\n",
    "                        state[i][j] = current_tile * 2\n",
    "                        state[i][j - 1] = 0\n",
    "                        # shift to the right other tiles\n",
    "                        for k in reversed(range(1, j - 1)):\n",
    "                            # current tile equal right tile\n",
    "                            state[i][j - k] = state[i][j - k - 1]\n",
    "                        # first cell is empty\n",
    "                        state[i][0] = 0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def transpose(self, array):\n",
    "        transposed_array = np.transpose(array)\n",
    "        return transposed_array\n",
    "\n",
    "    def swap(self, state, x1, y1, x2, y2):\n",
    "        # x and y are the position of the board matrix\n",
    "        z = state[x1][y1]\n",
    "        state[x1][y1] = state[x2][y2]\n",
    "        state[x2][y2] = z\n",
    "\n",
    "    # unit step on environment\n",
    "    def step(self, action):\n",
    "        old_state = self.__state\n",
    "        # state after agent action\n",
    "        self.__state = self.__calculate_transition(action)\n",
    "        observation = self.__state  # environment is fully observable\n",
    "        done = self.is_done()\n",
    "        reward = self.get_reward(self.__state)\n",
    "        info = {}  # optional debug info\n",
    "        return observation, done, reward, info\n",
    "\n",
    "    # render environment (board) on CLI\n",
    "    def render(self):\n",
    "        print_state = []\n",
    "        for item in self.__state:\n",
    "            print_state.append(['' if x==0 else x for x in item])\n",
    "        print(tabulate(print_state, tablefmt=\"grid\"))\n",
    "\n",
    "    # =========================================================\n",
    "    # public functions for agent to calculate optimal policy\n",
    "    # =========================================================\n",
    "\n",
    "    def get_possible_states(self):\n",
    "        return self.__possible_states\n",
    "\n",
    "    # get index of empty cells\n",
    "    def get_possible_actions(self, state=None):\n",
    "        if state is None:\n",
    "            state = self.__state\n",
    "\n",
    "        empty_cells = []\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                if self.__state[i][j] == 0:\n",
    "                    empty_cells.append([i, j])\n",
    "\n",
    "        return empty_cells\n",
    "\n",
    "    # determine wheter the game is over\n",
    "    # either: when all cells are occupied and no more merging is possible,\n",
    "    # or 2048 tile is generated\n",
    "    def is_done(self, state:np.ndarray = None):\n",
    "        if state is None:\n",
    "            state = self.__state\n",
    "\n",
    "        # detect if a tile has target value (e.g. 2048)\n",
    "        if self.target in state:\n",
    "            return True\n",
    "\n",
    "        # check if all cells are occupied and no more merging is possible\n",
    "        if 0 not in state:\n",
    "            # no more merging is possible\n",
    "            for i in range(self.board_size - 1):\n",
    "                for j in range(self.board_size - 1):\n",
    "                    if (state[i][j] == state[i + 1][j]) or (\n",
    "                        state[i][j] == state[i][j + 1]\n",
    "                    ):\n",
    "                        return False\n",
    "            # check bottom row\n",
    "            for j in range(self.board_size - 1):\n",
    "                if state[self.board_size - 1][j] == state[self.board_size - 1][j + 1]:\n",
    "                    return False\n",
    "\n",
    "            # check rightmost column\n",
    "            for i in range(self.board_size - 1):\n",
    "                if state[i][self.board_size - 1] == state[i + 1][self.board_size - 1]:\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    # Reward R(s) for every possible state\n",
    "    def get_reward(self, state):\n",
    "        # detect tile with target value (e.g. 2048 tile)\n",
    "        if self.target in state:\n",
    "            return 1\n",
    "        if not self.is_done(state):\n",
    "            return 0\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--+---+---+\n",
      "|  | 2 | 2 |\n",
      "+--+---+---+\n",
      "|  |   |   |\n",
      "+--+---+---+\n",
      "|  |   |   |\n",
      "+--+---+---+\n",
      "step 1) Action taken: Up, is done: False\n",
      "+--+---+---+\n",
      "|  | 2 | 2 |\n",
      "+--+---+---+\n",
      "|  | 4 |   |\n",
      "+--+---+---+\n",
      "|  |   |   |\n",
      "+--+---+---+\n",
      "step 2) Action taken: Down, is done: False\n",
      "+---+---+---+\n",
      "| 4 |   |   |\n",
      "+---+---+---+\n",
      "|   | 2 |   |\n",
      "+---+---+---+\n",
      "|   | 4 | 2 |\n",
      "+---+---+---+\n",
      "step 3) Action taken: Left, is done: False\n",
      "+---+---+---+\n",
      "| 4 |   | 4 |\n",
      "+---+---+---+\n",
      "| 2 |   |   |\n",
      "+---+---+---+\n",
      "| 4 | 2 |   |\n",
      "+---+---+---+\n",
      "step 4) Action taken: Left, is done: False\n",
      "+---+---+--+\n",
      "| 8 |   |  |\n",
      "+---+---+--+\n",
      "| 2 | 2 |  |\n",
      "+---+---+--+\n",
      "| 4 | 2 |  |\n",
      "+---+---+--+\n",
      "step 5) Action taken: Left, is done: False\n",
      "+---+---+--+\n",
      "| 8 | 4 |  |\n",
      "+---+---+--+\n",
      "| 4 |   |  |\n",
      "+---+---+--+\n",
      "| 4 | 2 |  |\n",
      "+---+---+--+\n",
      "step 6) Action taken: Left, is done: False\n",
      "+---+---+---+\n",
      "| 8 | 4 |   |\n",
      "+---+---+---+\n",
      "| 4 |   |   |\n",
      "+---+---+---+\n",
      "| 4 | 2 | 2 |\n",
      "+---+---+---+\n",
      "step 7) Action taken: Down, is done: False\n",
      "+---+---+---+\n",
      "| 2 |   |   |\n",
      "+---+---+---+\n",
      "|   | 4 |   |\n",
      "+---+---+---+\n",
      "| 8 | 2 | 2 |\n",
      "+---+---+---+\n",
      "step 8) Action taken: Right, is done: False\n",
      "+---+--+---+\n",
      "|   |  | 2 |\n",
      "+---+--+---+\n",
      "|   |  | 4 |\n",
      "+---+--+---+\n",
      "| 4 |  | 4 |\n",
      "+---+--+---+\n",
      "step 9) Action taken: Down, is done: False\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "| 4 | 2 | 8 |\n",
      "+---+---+---+\n",
      "step 10) Action taken: Up, is done: False\n",
      "+---+---+---+\n",
      "| 4 | 2 | 8 |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   | 2 |\n",
      "+---+---+---+\n",
      "step 11) Action taken: Down, is done: False\n",
      "+---+---+---+\n",
      "|   |   | 4 |\n",
      "+---+---+---+\n",
      "|   |   | 8 |\n",
      "+---+---+---+\n",
      "| 4 | 2 | 2 |\n",
      "+---+---+---+\n",
      "step 12) Action taken: Right, is done: False\n",
      "+--+---+---+\n",
      "|  |   | 4 |\n",
      "+--+---+---+\n",
      "|  | 2 | 8 |\n",
      "+--+---+---+\n",
      "|  |   | 4 |\n",
      "+--+---+---+\n",
      "step 13) Action taken: Right, is done: False\n",
      "+--+---+---+\n",
      "|  |   | 4 |\n",
      "+--+---+---+\n",
      "|  | 2 | 8 |\n",
      "+--+---+---+\n",
      "|  | 4 | 4 |\n",
      "+--+---+---+\n",
      "step 14) Action taken: Left, is done: False\n",
      "+---+---+---+\n",
      "| 4 |   | 2 |\n",
      "+---+---+---+\n",
      "| 2 | 8 |   |\n",
      "+---+---+---+\n",
      "| 8 |   |   |\n",
      "+---+---+---+\n",
      "step 15) Action taken: Up, is done: False\n",
      "+---+---+---+\n",
      "| 4 | 8 | 2 |\n",
      "+---+---+---+\n",
      "| 2 |   |   |\n",
      "+---+---+---+\n",
      "| 8 |   | 4 |\n",
      "+---+---+---+\n",
      "step 16) Action taken: Up, is done: False\n",
      "+---+---+---+\n",
      "| 4 | 8 | 2 |\n",
      "+---+---+---+\n",
      "| 2 |   | 4 |\n",
      "+---+---+---+\n",
      "| 8 |   | 4 |\n",
      "+---+---+---+\n",
      "step 17) Action taken: Left, is done: False\n",
      "+---+---+---+\n",
      "| 4 | 8 | 2 |\n",
      "+---+---+---+\n",
      "| 2 | 4 | 4 |\n",
      "+---+---+---+\n",
      "| 8 | 4 |   |\n",
      "+---+---+---+\n",
      "step 18) Action taken: Left, is done: False\n",
      "+---+---+---+\n",
      "| 4 | 8 | 2 |\n",
      "+---+---+---+\n",
      "| 2 | 8 | 2 |\n",
      "+---+---+---+\n",
      "| 8 | 4 |   |\n",
      "+---+---+---+\n",
      "step 19) Action taken: Right, is done: False\n",
      "+---+---+---+\n",
      "| 4 | 8 | 2 |\n",
      "+---+---+---+\n",
      "| 2 | 8 | 2 |\n",
      "+---+---+---+\n",
      "| 4 | 8 | 4 |\n",
      "+---+---+---+\n",
      "step 20) Action taken: Down, is done: False\n",
      "+---+----+---+\n",
      "| 4 | 2  |   |\n",
      "+---+----+---+\n",
      "| 2 |    | 4 |\n",
      "+---+----+---+\n",
      "| 4 | 16 | 4 |\n",
      "+---+----+---+\n",
      "step 21) Action taken: Up, is done: False\n",
      "+---+----+---+\n",
      "| 4 |  2 | 8 |\n",
      "+---+----+---+\n",
      "| 2 | 16 |   |\n",
      "+---+----+---+\n",
      "| 4 |  2 |   |\n",
      "+---+----+---+\n",
      "step 22) Action taken: Up, is done: False\n",
      "+---+----+---+\n",
      "| 4 |  2 | 8 |\n",
      "+---+----+---+\n",
      "| 2 | 16 | 2 |\n",
      "+---+----+---+\n",
      "| 4 |  2 |   |\n",
      "+---+----+---+\n",
      "step 23) Action taken: Up, is done: True\n",
      "+---+----+---+\n",
      "| 4 |  2 | 8 |\n",
      "+---+----+---+\n",
      "| 2 | 16 | 2 |\n",
      "+---+----+---+\n",
      "| 4 |  2 | 4 |\n",
      "+---+----+---+\n",
      "state = [[ 4  2  8]\n",
      " [ 2 16  2]\n",
      " [ 4  2  4]] , reward = -1 , done = True\n",
      "+---+----+---+\n",
      "| 4 |  2 | 8 |\n",
      "+---+----+---+\n",
      "| 2 | 16 | 2 |\n",
      "+---+----+---+\n",
      "| 4 |  2 | 4 |\n",
      "+---+----+---+\n",
      "possible (internal) game states:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of creation of an environment in the default state\n",
    "mdp = GameEnvironment(3, 64, [[0, 2, 2], [0, 0, 0], [0, 0, 0]])\n",
    "mdp.reset()\n",
    "mdp.render()\n",
    "\n",
    "i = 1\n",
    "while not mdp.is_done():\n",
    "    action = randint(1,4) # random choice\n",
    "    state, done, reward, info = mdp.step(Action(action))\n",
    "    print(f\"step {i}) Action taken: {Action(action)}, is done: {done}\")\n",
    "    mdp.render()\n",
    "    i=i+1\n",
    "\n",
    "# state, done, reward, info = mdp.step(Action(2))\n",
    "# mdp.render()\n",
    "# state, done, reward, info = mdp.step(Action.Right)\n",
    "# mdp.render()\n",
    "# state, done, reward, info = mdp.step(Action.Up)\n",
    "# print(\"UP\")\n",
    "# mdp.render()\n",
    "# state, done, reward, info = mdp.step(Action.Down)\n",
    "# print(\"Down\")\n",
    "# mdp.render()\n",
    "\n",
    "print('state =', state, ', reward =', reward, ', done =', done)\n",
    "mdp.render()\n",
    "print('possible (internal) game states:')\n",
    "mdp.get_possible_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--+---+---+\n",
      "|  | 2 | 2 |\n",
      "+--+---+---+\n",
      "|  |   |   |\n",
      "+--+---+---+\n",
      "|  |   |   |\n",
      "+--+---+---+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 0], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp = GameEnvironment(3, 64, [[0, 2, 2], [0, 0, 0], [0, 0, 0]])\n",
    "mdp.reset()\n",
    "mdp.render()\n",
    "mdp.get_possible_actions()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da3ec9ba63dac011d7c2149d03a658e24415e076227cdc43197121aae5b74ad2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
