{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate  # for rendering board\n",
    "from enum import Enum\n",
    "from random import randint, choice\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment possible actions: swipe to left, right, up, down\n",
    "class Action(Enum):\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    Left = 1\n",
    "    Right = 2\n",
    "    Up = 3\n",
    "    Down = 4\n",
    "\n",
    "\n",
    "class GameEnvironment:\n",
    "    def __init__(self, board_size=3, target=64, initial_state=None):\n",
    "        if initial_state == None:\n",
    "            # start with empty board\n",
    "            self.__initial_state = np.zeros([board_size, board_size] ,int)\n",
    "        else:\n",
    "            # copy to prevent aliassing\n",
    "            self.__initial_state = copy(initial_state)\n",
    "\n",
    "        # dynamic board size\n",
    "        self.board_size = board_size\n",
    "        self.target = target\n",
    "        self.__state = self.__initial_state\n",
    "        self.__possible_states = []\n",
    "        # maybe to remove\n",
    "        self.__calculate_possible_states(self.__initial_state)\n",
    "\n",
    "    # maybe to remove - iterate over all possible states\n",
    "    def __calculate_possible_states(self, state:np.ndarray = None, action=None, depth = 5):\n",
    "        if state is None:\n",
    "            state = self.__initial_state\n",
    "        \n",
    "        if action == None:\n",
    "            possible_actions = self.get_possible_actions()\n",
    "        else:\n",
    "            possible_actions = [action]\n",
    "            \n",
    "        # get all possible actions \n",
    "        for action in possible_actions:\n",
    "        # calculate the outcome state\n",
    "            outcome_state = self.__calculate_transition(state, action, new_tile=False)\n",
    "        # append to the self.__possible_states \n",
    "            empty_tiles = self.get_empty_tiles(outcome_state)\n",
    "            if len(empty_tiles) > 0:\n",
    "                # generate new tile at random empty cell\n",
    "                for tile in empty_tiles:\n",
    "                    new_state = deepcopy(outcome_state)   \n",
    "                    #if random generated tile is 2\n",
    "                    new_state[tile[0]][tile[1]] = 2\n",
    "                    temp_state = deepcopy(new_state)\n",
    "                    self.__possible_states.append(temp_state)\n",
    "                    if not self.is_done(temp_state) and depth > 0:\n",
    "                        depth -= 1\n",
    "                        self.__calculate_possible_states(deepcopy(temp_state),depth-1)\n",
    "                    #if random generated tile is 4\n",
    "                    new_state[tile[0]][tile[1]] = 4\n",
    "                    temp_state = deepcopy(new_state)\n",
    "                    self.__possible_states.append(temp_state)\n",
    "                    if not self.is_done(temp_state) and depth > 0:\n",
    "                        depth -= 1\n",
    "                        self.__calculate_possible_states(deepcopy(temp_state),depth-1)\n",
    "                    \n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.__state = self.__initial_state\n",
    "        return self.__state\n",
    "\n",
    "    # perform action on environment\n",
    "    def __calculate_transition(self, state:np.ndarray, action:Action, new_tile:bool = True):\n",
    "        if self.is_done(state):\n",
    "            return state\n",
    "        \n",
    "        new_state = deepcopy(state)\n",
    "\n",
    "        # 1. change the state to reflect the move by the agent,\n",
    "        # 2. merge same value tiles\n",
    "\n",
    "        # swipe to left\n",
    "        if action == Action.Left:\n",
    "            new_state = self.swipeToLeft(new_state)\n",
    "            new_state= self.mergeToLeft(new_state)\n",
    "        # swipe to right\n",
    "        elif action == Action.Right:\n",
    "            new_state = self.swipeToRight(new_state)\n",
    "            new_state = self.mergeToRight(new_state)\n",
    "        elif action == Action.Up:\n",
    "            # take transpose, swipe, then re-take transpose\n",
    "            temp_state = self.transpose(new_state)\n",
    "            temp_state = self.swipeToLeft(temp_state)\n",
    "            temp_state = self.mergeToLeft(temp_state)\n",
    "            new_state = self.transpose(temp_state)\n",
    "        elif action == Action.Down:\n",
    "            # take transpose\n",
    "            temp_state = self.transpose(new_state)\n",
    "            temp_state = self.swipeToRight(temp_state)\n",
    "            temp_state = self.mergeToRight(temp_state)\n",
    "            new_state = self.transpose(temp_state)\n",
    "\n",
    "        # 3. generate a new tile on empty cells\n",
    "        if new_tile:\n",
    "            empty_state = self.get_empty_tiles(new_state)\n",
    "\n",
    "            if len(empty_state) > 0:\n",
    "                # possible generated tile values\n",
    "                possible_gen_tiles = [2, 4]\n",
    "                # generate new tile at random empty cell\n",
    "                row, col = choice(empty_state)\n",
    "                new_state[row][col] = possible_gen_tiles[randint(0, 1)]\n",
    "\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    def swipeToLeft(self, state):\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                # [0,2,2]: if current cell is empty, swap with the right one\n",
    "                if state[i][j] == 0:\n",
    "\n",
    "                    # k is the offset of the first found tile\n",
    "                    for k in range(1, self.board_size - j):\n",
    "                        if state[i][j + k] != 0:\n",
    "                            self.swap(state, i, j, i, j + k)\n",
    "                            break\n",
    "        return state\n",
    "\n",
    "    def mergeToLeft(self, state):\n",
    "        # merge same tiles together\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    right_tile = state[i][j + 1]\n",
    "                    if right_tile == current_tile:\n",
    "                        # merge same tiles together\n",
    "                        state[i][j] = current_tile * 2\n",
    "                        state[i][j + 1] = 0\n",
    "                        # shift to the left other tiles\n",
    "                        for k in range(j + 1, self.board_size - 1):\n",
    "                            # current tile equal right tile\n",
    "                            state[i][j + k] = state[i][j + k + 1]\n",
    "\n",
    "                        # last cell is empty\n",
    "                        state[i][self.board_size - 1] = 0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def swipeToRight(self, state):\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                # [2,2,0]: if current cell is empty, swap with the left one\n",
    "                if state[i][j] == 0:\n",
    "\n",
    "                    # k is the offset of the first found tile\n",
    "                    for k in range(1, j + 1):\n",
    "                        if state[i][j - k] != 0:\n",
    "\n",
    "                            self.swap(state, i, j, i, j - k)\n",
    "                            break\n",
    "        return state\n",
    "\n",
    "    def mergeToRight(self, state):\n",
    "        # merge same tiles together\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    left_tile = state[i][j - 1]\n",
    "                    if left_tile == current_tile:\n",
    "                        # merge same tiles together\n",
    "                        state[i][j] = current_tile * 2\n",
    "                        state[i][j - 1] = 0\n",
    "                        # shift to the right other tiles\n",
    "                        for k in reversed(range(1, j - 1)):\n",
    "                            # current tile equal right tile\n",
    "                            state[i][j - k] = state[i][j - k - 1]\n",
    "                        # first cell is empty\n",
    "                        state[i][0] = 0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def transpose(self, array):\n",
    "        transposed_array = np.transpose(array)\n",
    "        return transposed_array\n",
    "\n",
    "    def swap(self, state, x1, y1, x2, y2):\n",
    "        # x and y are the position of the board matrix\n",
    "        z = state[x1][y1]\n",
    "        state[x1][y1] = state[x2][y2]\n",
    "        state[x2][y2] = z\n",
    "\n",
    "    # unit step on environment\n",
    "    def step(self, action):\n",
    "        old_state = self.__state\n",
    "        # state after agent action\n",
    "        self.__state = self.__calculate_transition(action)\n",
    "        observation = self.__state  # environment is fully observable\n",
    "        done = self.is_done()\n",
    "        reward = self.get_reward(self.__state)\n",
    "        info = {}  # optional    debug info\n",
    "        return observation, done, reward, info\n",
    "\n",
    "    # render environment (board) on CLI\n",
    "    def render(self,state:np.ndarray = None):\n",
    "        if state is None:\n",
    "            state = deepcopy(self.__state)\n",
    "        print_state = []\n",
    "        for item in state:\n",
    "            print_state.append(['' if x==0 else x for x in item])\n",
    "        print(tabulate(print_state, tablefmt=\"grid\"))\n",
    "\n",
    "    # =========================================================\n",
    "    # public functions for agent to calculate optimal policy\n",
    "    # =========================================================\n",
    "\n",
    "    def get_possible_states(self):\n",
    "        return self.__possible_states\n",
    "\n",
    "    # get index of empty cells\n",
    "    def get_empty_tiles(self, state=None):\n",
    "        if state is None:\n",
    "            state = self.__state\n",
    "        empty_cells = []\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                if state[i][j] == 0:\n",
    "                    empty_cells.append([i, j])\n",
    "\n",
    "        return empty_cells\n",
    "\n",
    "    def get_possible_actions(self, old_state:np.ndarray = None):\n",
    "        if old_state is None:\n",
    "            old_state = copy(self.__initial_state)\n",
    "\n",
    "        if self.is_done(old_state):\n",
    "            return []        \n",
    "        \n",
    "        return [Action.Left, Action.Right, Action.Up, Action.Down]\n",
    "        \n",
    "        possible_actions = []\n",
    "        \n",
    "        # Check whether 'swipe left' is possible or not\n",
    "        state = deepcopy(old_state)\n",
    "        state = self.swipeToLeft(state)\n",
    "        break_out_flag = False\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    right_tile = state[i][j + 1]\n",
    "                    if right_tile == current_tile:\n",
    "                        # left swipe merge is possible\n",
    "                        possible_actions.append(Action.Left)\n",
    "                        \n",
    "                        # exit from nested loop\n",
    "                        break_out_flag = True\n",
    "                        break\n",
    "                        \n",
    "            if break_out_flag:\n",
    "                break\n",
    "                \n",
    "        # Check whether 'swipe right' is possible or not\n",
    "        state = deepcopy(old_state)\n",
    "        state = self.swipeToRight(state)\n",
    "        break_out_flag = False\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    left_tile = state[i][j - 1]\n",
    "                    if left_tile == current_tile:\n",
    "                        # right swipe merge is possible\n",
    "                        possible_actions.append(Action.Right)\n",
    "                        \n",
    "                        # exit from nested loop\n",
    "                        break_out_flag = True\n",
    "                        break\n",
    "                        \n",
    "            if break_out_flag:\n",
    "                break\n",
    " \n",
    "        # Check whether 'swipe up' is possible or not\n",
    "        state = deepcopy(old_state)\n",
    "        state = self.transpose(state)\n",
    "        state = self.swipeToLeft(state)\n",
    "        break_out_flag = False\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    right_tile = state[i][j + 1]\n",
    "                    if right_tile == current_tile:\n",
    "                        # left swipe merge is possible\n",
    "                        possible_actions.append(Action.Up)\n",
    "                        \n",
    "                        # exit from nested loop\n",
    "                        break_out_flag = True\n",
    "                        break\n",
    "                        \n",
    "            if break_out_flag:\n",
    "                break\n",
    "        state = self.transpose(state)\n",
    " \n",
    "        # Check whether 'swipe down' is possible or not\n",
    "        state = deepcopy(old_state)\n",
    "        state = self.transpose(state)\n",
    "        state = self.swipeToRight(state)\n",
    "        break_out_flag = False\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    left_tile = state[i][j - 1]\n",
    "                    if left_tile == current_tile:\n",
    "                        # right swipe merge is possible\n",
    "                        possible_actions.append(Action.Down)\n",
    "                        \n",
    "                        # exit from nested loop\n",
    "                        break_out_flag = True\n",
    "                        break\n",
    "                        \n",
    "            if break_out_flag:\n",
    "                break\n",
    "        state = self.transpose(state)\n",
    "        \n",
    "        return possible_actions        \n",
    "        \n",
    "    # determine wheter the game is over\n",
    "    # either: when all cells are occupied and no more merging is possible,\n",
    "    # or 2048 tile is generated\n",
    "    def is_done(self, state:np.ndarray = None):\n",
    "        if state is None:\n",
    "            state = self.__state\n",
    "\n",
    "        # detect if a tile has target value (e.g. 2048)\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                if self.__state[i][j] == self.target:\n",
    "                    self.__won = True\n",
    "                    return True\n",
    "\n",
    "        # check if all cells are occupied and no more merging is possible\n",
    "        if 0 not in state:\n",
    "            # no more merging is possible\n",
    "            for i in range(self.board_size - 1):\n",
    "                for j in range(self.board_size - 1):\n",
    "                    if (state[i][j] == state[i + 1][j]) or (\n",
    "                        state[i][j] == state[i][j + 1]\n",
    "                    ):\n",
    "                        return False\n",
    "            # check bottom row\n",
    "            for j in range(self.board_size - 1):\n",
    "                if state[self.board_size - 1][j] == state[self.board_size - 1][j + 1]:\n",
    "                    return False\n",
    "\n",
    "            # check rightmost column\n",
    "            for i in range(self.board_size - 1):\n",
    "                if state[i][self.board_size - 1] == state[i + 1][self.board_size - 1]:\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "    # Reward R(s) for every possible state\n",
    "    def get_reward(self, state):\n",
    "        step_reward = 0.0\n",
    "        # detect tile with target value (e.g. 2048 tile)\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                if state[i][j] == self.target:\n",
    "                    return 1\n",
    "        # check if all cells are occupied and no more merging is possible\n",
    "        if 0 not in state:\n",
    "            # no more merging is possible\n",
    "            for i in range(self.board_size - 1):\n",
    "                for j in range(self.board_size - 1):\n",
    "                    if (state[i][j] == state[i + 1][j]) or (\n",
    "                        state[i][j] == state[i][j + 1]\n",
    "                    ):\n",
    "                        return step_reward\n",
    "            # check bottom row\n",
    "            for j in range(self.board_size - 1):\n",
    "                if state[self.board_size - 1][j] == state[self.board_size - 1][j + 1]:\n",
    "                    return step_reward\n",
    "            # check rightmost column\n",
    "            for i in range(self.board_size - 1):\n",
    "                if state[i][self.board_size - 1] == state[i + 1][self.board_size - 1]:\n",
    "                    return step_reward\n",
    "            return step_reward\n",
    "        # game is done\n",
    "        return -1\n",
    "\n",
    "    def get_transition_prob(self, action, new_state, old_state=None):\n",
    "        if old_state is None:\n",
    "            old_state = self.__state\n",
    "\n",
    "        # if the game is over, no transition can take place\n",
    "        if self.is_done(old_state):\n",
    "            return 0.0\n",
    "\n",
    "        # perform action on old_state\n",
    "        state_after_action = self.__calculate_transition(deepcopy(old_state), action)\n",
    "        # calculate possible states\n",
    "        self.__calculate_possible_states(deepcopy(old_state), action, depth=1)\n",
    "        possible_states_after_action = self.get_possible_states()\n",
    "        print(len(possible_states_after_action))\n",
    "        # check if game is done\n",
    "        # if self.is_done(state_after_action) and state_after_action == new_state:\n",
    "        #     # game is done and is won\n",
    "        #     if self.__won:\n",
    "        #         return 1.0\n",
    "        #     else:\n",
    "        #         return 0.0\n",
    "        \n",
    "        # transition probabilities\n",
    "        prob = 0\n",
    "        if possible_states_after_action is not None:\n",
    "            if new_state not in possible_states_after_action:\n",
    "                return 0.0\n",
    "            prob = possible_states_after_action.count(new_state) / (len(possible_states_after_action))\n",
    "            # print(f\"probability: {prob}\")\n",
    "        # else:\n",
    "        #     print(f\"None list. {action}\\n {state_after_action}\\n{possible_states_after_action}\")\n",
    "            # self.render(state_after_action)\n",
    "        \n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51142\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13768/1386096714.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     mdp.render(state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_possible_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transition_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13768/2368211529.py\u001b[0m in \u001b[0;36mget_transition_prob\u001b[1;34m(self, action, new_state, old_state)\u001b[0m\n\u001b[0;32m    420\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossible_states_after_action\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m             \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpossible_states_after_action\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossible_states_after_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m             \u001b[1;31m# print(f\"probability: {prob}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;31m# else:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "mdp = GameEnvironment(3, 64, [[0, 2, 2], [0, 0, 0], [0, 0, 2]])\n",
    "new_state = [[0, 2, 4], [0, 0, 0], [0, 0, 2]]\n",
    "# mdp.render()\n",
    "# for state in mdp.get_possible_states():\n",
    "#     mdp.render(state)\n",
    "for action in mdp.get_possible_actions():\n",
    "    print(mdp.get_transition_prob(action, new_state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of creation of an environment in the default state\n",
    "mdp = GameEnvironment(3, 64, [[0, 2, 2], [0, 0, 0], [0, 0, 0]])\n",
    "mdp.reset()\n",
    "mdp.render()\n",
    "\n",
    "i = 1\n",
    "while not mdp.is_done():\n",
    "    action = randint(1,4) # random choice\n",
    "    state, done, reward, info = mdp.step(Action(action))\n",
    "    print(f\"step {i}) Action taken: {Action(action)}, is done: {done}\")\n",
    "    mdp.render()\n",
    "    i=i+1\n",
    "\n",
    "print('state =', state, ', reward =', reward, ', done =', done)\n",
    "mdp.render()\n",
    "print('possible (internal) game states:')\n",
    "mdp.get_possible_states()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da3ec9ba63dac011d7c2149d03a658e24415e076227cdc43197121aae5b74ad2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
