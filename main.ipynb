{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate  # for rendering board\n",
    "from enum import Enum\n",
    "from random import randint, choice\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment possible actions: swipe to left, right, up, down\n",
    "class Action(Enum):\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    Left = 1\n",
    "    Right = 2\n",
    "    Up = 3\n",
    "    Down = 4\n",
    "\n",
    "\n",
    "class GameEnvironment:\n",
    "    def __init__(self, board_size=3, target=64, initial_state=None):\n",
    "        if initial_state == None:\n",
    "            # start with empty board\n",
    "            self.__initial_state = np.zeros([board_size, board_size] ,int)\n",
    "        else:\n",
    "            # copy to prevent aliassing\n",
    "            self.__initial_state = copy(initial_state)\n",
    "\n",
    "        # dynamic board size\n",
    "        self.board_size = board_size\n",
    "        self.target = target\n",
    "        self.__state = self.__initial_state\n",
    "        self.__possible_states = []\n",
    "        # maybe to remove\n",
    "        self.__calculate_possible_states(self.__initial_state, depth=0)\n",
    "\n",
    "    # maybe to remove - iterate over all possible states\n",
    "    def __calculate_possible_states(self, state:np.ndarray = None, action=None, depth = 5):\n",
    "        tile_2_depth = copy(depth)\n",
    "        tile_4_depth = copy(depth)\n",
    "        if state is None:\n",
    "            state = self.__initial_state\n",
    "        \n",
    "        if action == None:\n",
    "            possible_actions = self.get_possible_actions()\n",
    "        else:\n",
    "            possible_actions = [action]\n",
    "            \n",
    "        # get all possible actions \n",
    "        for action in possible_actions:\n",
    "        # calculate the outcome state\n",
    "            outcome_state = self.__calculate_transition(action, state, new_tile=False)\n",
    "        # append to the self.__possible_states \n",
    "            empty_tiles = self.get_empty_tiles(outcome_state)\n",
    "            if len(empty_tiles) > 0:\n",
    "                # generate new tile at random empty cell\n",
    "                for tile in empty_tiles:\n",
    "                    new_state = deepcopy(outcome_state)   \n",
    "                    #if random generated tile is 2\n",
    "                    new_state[tile[0]][tile[1]] = 2\n",
    "                    temp_state = deepcopy(new_state)\n",
    "                    self.__possible_states.append(temp_state)\n",
    "                    if not self.is_done(temp_state) and tile_2_depth > 0:\n",
    "                        self.__calculate_possible_states(deepcopy(temp_state),depth= tile_2_depth - 1)\n",
    "                    #if random generated tile is 4\n",
    "                    new_state[tile[0]][tile[1]] = 4\n",
    "                    temp_state = deepcopy(new_state)\n",
    "                    self.__possible_states.append(temp_state)\n",
    "                    if not self.is_done(temp_state) and tile_4_depth > 0:\n",
    "                        self.__calculate_possible_states(deepcopy(temp_state),depth = tile_4_depth - 1)\n",
    "                    \n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.__state = self.__initial_state\n",
    "        return self.__state\n",
    "\n",
    "    # perform action on environment\n",
    "    def __calculate_transition(self, action:Action, state:np.ndarray=None, new_tile:bool = True):        \n",
    "        if state is None:\n",
    "            new_state = self.__state\n",
    "        else:\n",
    "            new_state = deepcopy(state)\n",
    "            \n",
    "        if self.is_done(state):\n",
    "            return new_state\n",
    "\n",
    "        # 1. change the state to reflect the move by the agent,\n",
    "        # 2. merge same value tiles\n",
    "\n",
    "        # swipe to left\n",
    "        if action == Action.Left:\n",
    "            new_state = self.swipeToLeft(new_state)\n",
    "            new_state= self.mergeToLeft(new_state)\n",
    "        # swipe to right\n",
    "        elif action == Action.Right:\n",
    "            new_state = self.swipeToRight(new_state)\n",
    "            new_state = self.mergeToRight(new_state)\n",
    "        elif action == Action.Up:\n",
    "            # take transpose, swipe, then re-take transpose\n",
    "            temp_state = self.transpose(new_state)\n",
    "            temp_state = self.swipeToLeft(temp_state)\n",
    "            temp_state = self.mergeToLeft(temp_state)\n",
    "            new_state = self.transpose(temp_state)\n",
    "        elif action == Action.Down:\n",
    "            # take transpose\n",
    "            temp_state = self.transpose(new_state)\n",
    "            temp_state = self.swipeToRight(temp_state)\n",
    "            temp_state = self.mergeToRight(temp_state)\n",
    "            new_state = self.transpose(temp_state)\n",
    "\n",
    "        # 3. generate a new tile on empty cells\n",
    "        if new_tile:\n",
    "            empty_state = self.get_empty_tiles(new_state)\n",
    "\n",
    "            if len(empty_state) > 0:\n",
    "                # possible generated tile values\n",
    "                possible_gen_tiles = [2, 4]\n",
    "                # generate new tile at random empty cell\n",
    "                row, col = choice(empty_state)\n",
    "                new_state[row][col] = possible_gen_tiles[randint(0, 1)]\n",
    "\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    def swipeToLeft(self, state):\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                # [0,2,2]: if current cell is empty, swap with the right one\n",
    "                if state[i][j] == 0:\n",
    "\n",
    "                    # k is the offset of the first found tile\n",
    "                    for k in range(1, self.board_size - j):\n",
    "                        if state[i][j + k] != 0:\n",
    "                            self.swap(state, i, j, i, j + k)\n",
    "                            break\n",
    "        return state\n",
    "\n",
    "    def mergeToLeft(self, state):\n",
    "        # merge same tiles together\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    right_tile = state[i][j + 1]\n",
    "                    if right_tile == current_tile:\n",
    "                        # merge same tiles together\n",
    "                        state[i][j] = current_tile * 2\n",
    "                        state[i][j + 1] = 0\n",
    "                        # shift to the left other tiles\n",
    "                        for k in range(j + 1, self.board_size - 1):\n",
    "                            # current tile equal right tile\n",
    "                            state[i][j + k] = state[i][j + k + 1]\n",
    "\n",
    "                        # last cell is empty\n",
    "                        state[i][self.board_size - 1] = 0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def swipeToRight(self, state):\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                # [2,2,0]: if current cell is empty, swap with the left one\n",
    "                if state[i][j] == 0:\n",
    "\n",
    "                    # k is the offset of the first found tile\n",
    "                    for k in range(1, j + 1):\n",
    "                        if state[i][j - k] != 0:\n",
    "\n",
    "                            self.swap(state, i, j, i, j - k)\n",
    "                            break\n",
    "        return state\n",
    "\n",
    "    def mergeToRight(self, state):\n",
    "        # merge same tiles together\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    left_tile = state[i][j - 1]\n",
    "                    if left_tile == current_tile:\n",
    "                        # merge same tiles together\n",
    "                        state[i][j] = current_tile * 2\n",
    "                        state[i][j - 1] = 0\n",
    "                        # shift to the right other tiles\n",
    "                        for k in reversed(range(1, j - 1)):\n",
    "                            # current tile equal right tile\n",
    "                            state[i][j - k] = state[i][j - k - 1]\n",
    "                        # first cell is empty\n",
    "                        state[i][0] = 0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def transpose(self, array):\n",
    "        transposed_array = np.transpose(array)\n",
    "        return transposed_array\n",
    "\n",
    "    def swap(self, state, x1, y1, x2, y2):\n",
    "        # x and y are the position of the board matrix\n",
    "        z = state[x1][y1]\n",
    "        state[x1][y1] = state[x2][y2]\n",
    "        state[x2][y2] = z\n",
    "\n",
    "    # unit step on environment\n",
    "    def step(self, action):\n",
    "        old_state = self.__state\n",
    "        # state after agent action\n",
    "        self.__state = self.__calculate_transition(action)\n",
    "        observation = self.__state  # environment is fully observable\n",
    "        done = self.is_done()\n",
    "        reward = self.get_reward(self.__state)\n",
    "        info = {}  # optional    debug info\n",
    "        return observation, done, reward, info\n",
    "\n",
    "    # render environment (board) on CLI\n",
    "    def render(self,state:np.ndarray = None):\n",
    "        if state is None:\n",
    "            state = deepcopy(self.__state)\n",
    "        print_state = []\n",
    "        for item in state:\n",
    "            print_state.append(['' if x==0 else x for x in item])\n",
    "        print(tabulate(print_state, tablefmt=\"grid\"))\n",
    "\n",
    "    # =========================================================\n",
    "    # public functions for agent to calculate optimal policy\n",
    "    # =========================================================\n",
    "\n",
    "    def get_possible_states(self):\n",
    "        return self.__possible_states\n",
    "\n",
    "    # get index of empty cells\n",
    "    def get_empty_tiles(self, state=None):\n",
    "        if state is None:\n",
    "            state = self.__state\n",
    "        empty_cells = []\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                if state[i][j] == 0:\n",
    "                    empty_cells.append([i, j])\n",
    "\n",
    "        return empty_cells\n",
    "\n",
    "    def get_possible_actions(self, old_state:np.ndarray = None):\n",
    "        if old_state is None:\n",
    "            old_state = copy(self.__initial_state)\n",
    "\n",
    "        if self.is_done(old_state):\n",
    "            return []        \n",
    "        \n",
    "        return [Action.Left, Action.Right, Action.Up, Action.Down]\n",
    "        \n",
    "        possible_actions = []\n",
    "        \n",
    "        # Check whether 'swipe left' is possible or not\n",
    "        state = deepcopy(old_state)\n",
    "        state = self.swipeToLeft(state)\n",
    "        break_out_flag = False\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    right_tile = state[i][j + 1]\n",
    "                    if right_tile == current_tile:\n",
    "                        # left swipe merge is possible\n",
    "                        possible_actions.append(Action.Left)\n",
    "                        \n",
    "                        # exit from nested loop\n",
    "                        break_out_flag = True\n",
    "                        break\n",
    "                        \n",
    "            if break_out_flag:\n",
    "                break\n",
    "                \n",
    "        # Check whether 'swipe right' is possible or not\n",
    "        state = deepcopy(old_state)\n",
    "        state = self.swipeToRight(state)\n",
    "        break_out_flag = False\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    left_tile = state[i][j - 1]\n",
    "                    if left_tile == current_tile:\n",
    "                        # right swipe merge is possible\n",
    "                        possible_actions.append(Action.Right)\n",
    "                        \n",
    "                        # exit from nested loop\n",
    "                        break_out_flag = True\n",
    "                        break\n",
    "                        \n",
    "            if break_out_flag:\n",
    "                break\n",
    " \n",
    "        # Check whether 'swipe up' is possible or not\n",
    "        state = deepcopy(old_state)\n",
    "        state = self.transpose(state)\n",
    "        state = self.swipeToLeft(state)\n",
    "        break_out_flag = False\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size - 1):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    right_tile = state[i][j + 1]\n",
    "                    if right_tile == current_tile:\n",
    "                        # left swipe merge is possible\n",
    "                        possible_actions.append(Action.Up)\n",
    "                        \n",
    "                        # exit from nested loop\n",
    "                        break_out_flag = True\n",
    "                        break\n",
    "                        \n",
    "            if break_out_flag:\n",
    "                break\n",
    "        state = self.transpose(state)\n",
    " \n",
    "        # Check whether 'swipe down' is possible or not\n",
    "        state = deepcopy(old_state)\n",
    "        state = self.transpose(state)\n",
    "        state = self.swipeToRight(state)\n",
    "        break_out_flag = False\n",
    "        for i in range(self.board_size):\n",
    "            for j in reversed(range(1, self.board_size)):\n",
    "                current_tile = state[i][j]\n",
    "                if current_tile != 0:\n",
    "                    left_tile = state[i][j - 1]\n",
    "                    if left_tile == current_tile:\n",
    "                        # right swipe merge is possible\n",
    "                        possible_actions.append(Action.Down)\n",
    "                        \n",
    "                        # exit from nested loop\n",
    "                        break_out_flag = True\n",
    "                        break\n",
    "                        \n",
    "            if break_out_flag:\n",
    "                break\n",
    "        state = self.transpose(state)\n",
    "        \n",
    "        return possible_actions        \n",
    "        \n",
    "    # determine wheter the game is over\n",
    "    # either: when all cells are occupied and no more merging is possible,\n",
    "    # or 2048 tile is generated\n",
    "    def is_done(self, state:np.ndarray = None):\n",
    "        if state is None:\n",
    "            state = self.__state\n",
    "\n",
    "        # detect if a tile has target value (e.g. 2048)\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                if self.__state[i][j] == self.target:\n",
    "                    self.__won = True\n",
    "                    return True\n",
    "\n",
    "        # check if all cells are occupied and no more merging is possible\n",
    "        if 0 not in state:\n",
    "            # no more merging is possible\n",
    "            for i in range(self.board_size - 1):\n",
    "                for j in range(self.board_size - 1):\n",
    "                    if (state[i][j] == state[i + 1][j]) or (\n",
    "                        state[i][j] == state[i][j + 1]\n",
    "                    ):\n",
    "                        return False\n",
    "            # check bottom row\n",
    "            for j in range(self.board_size - 1):\n",
    "                if state[self.board_size - 1][j] == state[self.board_size - 1][j + 1]:\n",
    "                    return False\n",
    "\n",
    "            # check rightmost column\n",
    "            for i in range(self.board_size - 1):\n",
    "                if state[i][self.board_size - 1] == state[i + 1][self.board_size - 1]:\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "    # Reward R(s) for every possible state\n",
    "    def get_reward(self, state):\n",
    "        # detect tile with target value (e.g. 2048 tile)\n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                if state[i][j] == self.target:\n",
    "                    return 1\n",
    "        \n",
    "        score_reward = 0.0\n",
    "        \n",
    "        for i in range(self.board_size):\n",
    "            for j in range(self.board_size):\n",
    "                score_reward += state[i][j]\n",
    "        \n",
    "        score_reward = score_reward/(self.target*self.board_size*2)\n",
    "        \n",
    "        # check if all cells are occupied and no more merging is possible\n",
    "        if 0 not in state:\n",
    "            # no more merging is possible\n",
    "            for i in range(self.board_size - 1):\n",
    "                for j in range(self.board_size - 1):\n",
    "                    if (state[i][j] == state[i + 1][j]) or (\n",
    "                        state[i][j] == state[i][j + 1]\n",
    "                    ):\n",
    "                        return score_reward\n",
    "            # check bottom row\n",
    "            for j in range(self.board_size - 1):\n",
    "                if state[self.board_size - 1][j] == state[self.board_size - 1][j + 1]:\n",
    "                    return score_reward\n",
    "            # check rightmost column\n",
    "            for i in range(self.board_size - 1):\n",
    "                if state[i][self.board_size - 1] == state[i + 1][self.board_size - 1]:\n",
    "                    return score_reward\n",
    "            return score_reward\n",
    "            \n",
    "        # game is done\n",
    "        return -1\n",
    "\n",
    "    def get_transition_prob(self, action, new_state, old_state=None):\n",
    "        if old_state is None:\n",
    "            old_state = self.__state\n",
    "\n",
    "        # if the game is over, no transition can take place\n",
    "        if self.is_done(old_state):\n",
    "            return 0.0\n",
    "\n",
    "        # perform action on old_state\n",
    "        state_after_action = self.__calculate_transition(action, deepcopy(old_state))\n",
    "        # calculate possible states\n",
    "        self.__calculate_possible_states(deepcopy(old_state), action, depth=0)\n",
    "        possible_states_after_action = self.get_possible_states()\n",
    "        # print(len(possible_states_after_action))\n",
    "        \n",
    "        # check if game is done\n",
    "        # if self.is_done(state_after_action) and state_after_action == new_state:\n",
    "        #     # game is done and is won\n",
    "        #     if self.__won:\n",
    "        #         return 1.0\n",
    "        #     else:\n",
    "        #         return 0.0\n",
    "        \n",
    "        # transition probabilities\n",
    "        prob = 0\n",
    "        if possible_states_after_action is not None:\n",
    "            if new_state not in possible_states_after_action:\n",
    "                return 0.0\n",
    "            prob = self.count(possible_states_after_action, new_state) / (len(possible_states_after_action))\n",
    "            # print(f\"probability: {prob}\")\n",
    "        # else:\n",
    "        #     print(f\"None list. {action}\\n {state_after_action}\\n{possible_states_after_action}\")\n",
    "            # self.render(state_after_action)\n",
    "        \n",
    "        \n",
    "        return prob\n",
    "    def count(self, list, value):\n",
    "        count = 0\n",
    "        for x in list:\n",
    "            if np.array_equal(x, value):\n",
    "                count += 1\n",
    "        return count    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.857142857142857, action: Left\n",
      "3.571428571428571, action: Right\n",
      "4.081632653061225, action: Up\n",
      "3.571428571428571, action: Down\n"
     ]
    }
   ],
   "source": [
    "# test tran prob\n",
    "mdp = GameEnvironment(3, 64, [[0, 2, 2], [0, 0, 0], [0, 0, 2]])\n",
    "new_state = [[0, 2, 4], [0, 0, 0], [0, 0, 2]]\n",
    "for action in mdp.get_possible_actions():\n",
    "    print(f\"{mdp.get_transition_prob(action, new_state)*100}, action: {action}\")\n",
    "# mdp.render()\n",
    "# mdp.render(new_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--+---+---+\n",
      "|  | 2 | 2 |\n",
      "+--+---+---+\n",
      "|  |   |   |\n",
      "+--+---+---+\n",
      "|  |   |   |\n",
      "+--+---+---+\n",
      "2\n",
      "step 1) Action taken: Up, is done: False\n",
      "+---+---+---+\n",
      "|   | 2 | 2 |\n",
      "+---+---+---+\n",
      "| 2 |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "step 2) Action taken: Left, is done: False\n",
      "+---+---+--+\n",
      "| 4 | 4 |  |\n",
      "+---+---+--+\n",
      "| 2 |   |  |\n",
      "+---+---+--+\n",
      "|   |   |  |\n",
      "+---+---+--+\n",
      "step 3) Action taken: Right, is done: False\n",
      "+---+--+---+\n",
      "| 2 |  | 8 |\n",
      "+---+--+---+\n",
      "|   |  | 2 |\n",
      "+---+--+---+\n",
      "|   |  |   |\n",
      "+---+--+---+\n",
      "step 4) Action taken: Left, is done: False\n",
      "+---+---+--+\n",
      "| 2 | 8 |  |\n",
      "+---+---+--+\n",
      "| 2 | 4 |  |\n",
      "+---+---+--+\n",
      "|   |   |  |\n",
      "+---+---+--+\n",
      "step 5) Action taken: Right, is done: False\n",
      "+---+---+---+\n",
      "| 2 | 2 | 8 |\n",
      "+---+---+---+\n",
      "|   | 2 | 4 |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "step 6) Action taken: Right, is done: False\n",
      "+---+---+---+\n",
      "| 2 | 4 | 8 |\n",
      "+---+---+---+\n",
      "|   | 2 | 4 |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "step 7) Action taken: Left, is done: False\n",
      "+---+---+---+\n",
      "| 2 | 4 | 8 |\n",
      "+---+---+---+\n",
      "| 2 | 4 | 2 |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "step 8) Action taken: Down, is done: False\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "| 2 |   | 8 |\n",
      "+---+---+---+\n",
      "| 4 | 8 | 2 |\n",
      "+---+---+---+\n",
      "step 9) Action taken: Down, is done: False\n",
      "+---+---+---+\n",
      "| 4 |   |   |\n",
      "+---+---+---+\n",
      "| 2 |   | 8 |\n",
      "+---+---+---+\n",
      "| 4 | 8 | 2 |\n",
      "+---+---+---+\n",
      "step 10) Action taken: Left, is done: False\n",
      "+---+---+---+\n",
      "| 4 |   | 2 |\n",
      "+---+---+---+\n",
      "| 2 | 8 |   |\n",
      "+---+---+---+\n",
      "| 4 | 8 | 2 |\n",
      "+---+---+---+\n",
      "step 11) Action taken: Up, is done: False\n",
      "+---+----+---+\n",
      "| 4 | 16 | 4 |\n",
      "+---+----+---+\n",
      "| 2 |    | 2 |\n",
      "+---+----+---+\n",
      "| 4 |    |   |\n",
      "+---+----+---+\n",
      "step 12) Action taken: Left, is done: False\n",
      "+---+----+---+\n",
      "| 4 | 16 | 4 |\n",
      "+---+----+---+\n",
      "| 4 |    | 2 |\n",
      "+---+----+---+\n",
      "| 4 |    |   |\n",
      "+---+----+---+\n",
      "step 13) Action taken: Up, is done: False\n",
      "+---+----+---+\n",
      "| 8 | 16 | 4 |\n",
      "+---+----+---+\n",
      "| 4 |    | 2 |\n",
      "+---+----+---+\n",
      "|   | 2  |   |\n",
      "+---+----+---+\n",
      "step 14) Action taken: Up, is done: False\n",
      "+---+----+---+\n",
      "| 8 | 16 | 4 |\n",
      "+---+----+---+\n",
      "| 4 | 2  | 2 |\n",
      "+---+----+---+\n",
      "|   |    | 4 |\n",
      "+---+----+---+\n",
      "step 15) Action taken: Right, is done: False\n",
      "+---+----+---+\n",
      "| 8 | 16 | 4 |\n",
      "+---+----+---+\n",
      "|   |    | 4 |\n",
      "+---+----+---+\n",
      "| 4 |    | 4 |\n",
      "+---+----+---+\n",
      "step 16) Action taken: Right, is done: False\n",
      "+---+----+---+\n",
      "| 8 | 16 | 4 |\n",
      "+---+----+---+\n",
      "| 2 |    | 4 |\n",
      "+---+----+---+\n",
      "|   |    | 8 |\n",
      "+---+----+---+\n",
      "step 17) Action taken: Down, is done: False\n",
      "+---+----+---+\n",
      "|   |    |   |\n",
      "+---+----+---+\n",
      "| 8 | 4  | 8 |\n",
      "+---+----+---+\n",
      "| 2 | 16 | 8 |\n",
      "+---+----+---+\n",
      "step 18) Action taken: Down, is done: False\n",
      "+---+----+----+\n",
      "|   |  2 |    |\n",
      "+---+----+----+\n",
      "| 8 |  4 |    |\n",
      "+---+----+----+\n",
      "| 2 | 16 | 16 |\n",
      "+---+----+----+\n",
      "step 19) Action taken: Left, is done: False\n",
      "+---+----+---+\n",
      "| 2 |    |   |\n",
      "+---+----+---+\n",
      "| 8 | 4  | 4 |\n",
      "+---+----+---+\n",
      "| 2 | 32 |   |\n",
      "+---+----+---+\n",
      "step 20) Action taken: Down, is done: False\n",
      "+---+----+---+\n",
      "| 2 |  4 |   |\n",
      "+---+----+---+\n",
      "| 8 |  4 |   |\n",
      "+---+----+---+\n",
      "| 2 | 32 | 4 |\n",
      "+---+----+---+\n",
      "step 21) Action taken: Right, is done: False\n",
      "+---+----+---+\n",
      "| 2 |  2 | 4 |\n",
      "+---+----+---+\n",
      "|   |  8 | 4 |\n",
      "+---+----+---+\n",
      "| 2 | 32 | 4 |\n",
      "+---+----+---+\n",
      "step 22) Action taken: Up, is done: False\n",
      "+---+----+---+\n",
      "| 4 |  2 | 8 |\n",
      "+---+----+---+\n",
      "|   |  8 | 4 |\n",
      "+---+----+---+\n",
      "|   | 32 | 2 |\n",
      "+---+----+---+\n",
      "step 23) Action taken: Right, is done: False\n",
      "+---+----+---+\n",
      "| 4 |  2 | 8 |\n",
      "+---+----+---+\n",
      "|   |  8 | 4 |\n",
      "+---+----+---+\n",
      "| 2 | 32 | 2 |\n",
      "+---+----+---+\n",
      "step 24) Action taken: Up, is done: True\n",
      "+---+----+---+\n",
      "| 4 |  2 | 8 |\n",
      "+---+----+---+\n",
      "| 2 |  8 | 4 |\n",
      "+---+----+---+\n",
      "| 4 | 32 | 2 |\n",
      "+---+----+---+\n",
      "state = [[ 4  2  8]\n",
      " [ 2  8  4]\n",
      " [ 4 32  2]] , reward = 0.171875 , done = True\n"
     ]
    }
   ],
   "source": [
    "# example of creation of an environment in the default state\n",
    "mdp = GameEnvironment(3, 64, [[0, 2, 2], [0, 0, 0], [0, 0, 0]])\n",
    "mdp.reset()\n",
    "mdp.render()\n",
    "\n",
    "i = 1\n",
    "while not mdp.is_done():\n",
    "    action = randint(1,4) # random choice\n",
    "    state, done, reward, info = mdp.step(Action(action))\n",
    "    print(f\"step {i}) Action taken: {Action(action)}, is done: {done}\")\n",
    "    mdp.render()\n",
    "    i=i+1\n",
    "\n",
    "print('state =', state, ', reward =', reward, ', done =', done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Utility\n",
      "88\n",
      "104\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22376/1555766957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mmdp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGameEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"start Utility\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mValueIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value iteration done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22376/1555766957.py\u001b[0m in \u001b[0;36mValueIteration\u001b[1;34m(mdp, error)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mmax_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_possible_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ_Value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_a\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                     \u001b[0mmax_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22376/1555766957.py\u001b[0m in \u001b[0;36mQ_Value\u001b[1;34m(mdp, s, a, U)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms_p\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_possible_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transition_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mutilityValue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUtility\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindUtilityValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22376/602030944.py\u001b[0m in \u001b[0;36mget_transition_prob\u001b[1;34m(self, action, new_state, old_state)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpossible_states_after_action\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossible_states_after_action\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossible_states_after_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossible_states_after_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "class Utility:\n",
    "    def __init__(self, state, value):\n",
    "        self.__state = state\n",
    "        self.value = value\n",
    "        \n",
    "    def get_state(self):\n",
    "        return self.__state\n",
    "    \n",
    "    @staticmethod\n",
    "    def findUtilityValue(list, search_state):\n",
    "        for x in list:\n",
    "            if np.array_equal(x, search_state):\n",
    "                return x.value\n",
    "        return None\n",
    "\n",
    "def get_initial_U(mdp):\n",
    "    U = []\n",
    "    for s in mdp.get_possible_states():\n",
    "        U.append(Utility(s, mdp.get_reward(s))) \n",
    "    return U\n",
    "    \n",
    "def Q_Value(mdp, s, a, U):\n",
    "    Q = 0.0\n",
    "    for s_p in mdp.get_possible_states():\n",
    "        P = mdp.get_transition_prob(a, s_p, s)\n",
    "        R = mdp.get_reward(s_p)\n",
    "        utilityValue = Utility.findUtilityValue(U, s_p)\n",
    "        if utilityValue is None:\n",
    "            utilityValue = 0\n",
    "        Q += P * (R + utilityValue)\n",
    "    return Q\n",
    "\n",
    "def ValueIteration(mdp, error=0.00001):\n",
    "    # from AIMA 4th edition without discount gamma \n",
    "    U_p = get_initial_U(mdp) # U_p = U'\n",
    "    delta = float('inf')\n",
    "    while delta > error:\n",
    "        U = deepcopy(U_p)\n",
    "        \n",
    "        # print_U(U)  # to illustrate the iteration process\n",
    "        delta = 0\n",
    "        for s in mdp.get_possible_states():\n",
    "            max_a = float('-inf')\n",
    "            for a in mdp.get_possible_actions(s):\n",
    "                q = Q_Value(mdp, s, a, U) \n",
    "                if q > max_a:\n",
    "                    max_a = q\n",
    "            U_p[tuple(s)] = max_a\n",
    "            if abs(U_p[tuple(s)] - U[tuple(s)]) > delta:\n",
    "                delta = abs(U_p[tuple(s)] - U[tuple(s)])\n",
    "        # test\n",
    "        error = -100\n",
    "    return U\n",
    "    \n",
    "def print_policy(pi):\n",
    "    print('Policy:')\n",
    "    for y in range (3, 0, -1):\n",
    "        for x in range(1, 5):\n",
    "            s = (x, y)\n",
    "            if s in pi:\n",
    "                print('   {}: {:12}'.format(s, pi[s]), end = '')\n",
    "            else: # preserve alignment\n",
    "                print(' '*23, end = '')\n",
    "        print()\n",
    "\n",
    "mdp = GameEnvironment()\n",
    "print(\"start Utility\")\n",
    "U = ValueIteration(mdp)\n",
    "print(\"value iteration done\")\n",
    "print(U)\n",
    "pi_star = {}\n",
    "for s in mdp.get_possible_states():\n",
    "    if mdp.is_done(s):\n",
    "        continue # policy is not needed in stop states\n",
    "    max_a = float('-inf')\n",
    "    argmax_a = None\n",
    "    for action in Action:\n",
    "        q = Q_Value(mdp, s, action, U) \n",
    "        if q > max_a:\n",
    "            max_a = q\n",
    "            argmax_a = action\n",
    "    pi_star[s] = argmax_a\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da3ec9ba63dac011d7c2149d03a658e24415e076227cdc43197121aae5b74ad2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
